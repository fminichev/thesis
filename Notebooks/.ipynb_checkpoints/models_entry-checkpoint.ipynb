{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0119ac3d",
   "metadata": {},
   "source": [
    "# Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d1d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "plt.rcParams[\"image.cmap\"] = \"viridis\"\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.discrete.discrete_model import Probit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_score, recall_score\n",
    "from catboost.utils import get_roc_curve\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616626aa",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72fc816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2013_2014 = pd.read_csv('../data_preprocessed/data_2013_2014.csv')\n",
    "df_2014_2015 = pd.read_csv('../data_preprocessed/data_2014_2015.csv')\n",
    "df_2015_2016 = pd.read_csv('../data_preprocessed/data_2015_2016.csv')\n",
    "df_2016_2017 = pd.read_csv('../data_preprocessed/data_2016_2017.csv')\n",
    "df_2017_2018 = pd.read_csv('../data_preprocessed/data_2017_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e2b13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df_2013_2014,df_2014_2015,df_2015_2016,\n",
    "                 df_2016_2017,df_2017_2018]).astype({'neigh_airports_pr_period':'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1038a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51894, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131f8643",
   "metadata": {},
   "source": [
    "# Пробит и Логит обычные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "451a7a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.031942\n",
      "         Iterations 9\n",
      "                          Probit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                38920\n",
      "Model:                         Probit   Df Residuals:                    38912\n",
      "Method:                           MLE   Df Model:                            7\n",
      "Date:                Thu, 05 May 2022   Pseudo R-squ.:                  0.1605\n",
      "Time:                        00:49:24   Log-Likelihood:                -1243.2\n",
      "converged:                       True   LL-Null:                       -1480.8\n",
      "Covariance Type:                  HC0   LLR p-value:                 1.655e-98\n",
      "=============================================================================================\n",
      "                                coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------\n",
      "const                        -2.7386      0.085    -32.409      0.000      -2.904      -2.573\n",
      "served_airports_pr_period     0.0028      0.004      0.661      0.509      -0.005       0.011\n",
      "neigh_airports_pr_period      0.0839      0.007     12.114      0.000       0.070       0.097\n",
      "airport_type                  0.0883      0.046      1.926      0.054      -0.002       0.178\n",
      "population                 7.124e-05   2.08e-05      3.427      0.001    3.05e-05       0.000\n",
      "megapolis                    -0.1014      0.049     -2.051      0.040      -0.198      -0.004\n",
      "tourist                       0.3124      0.057      5.512      0.000       0.201       0.424\n",
      "distance_km               -6.451e-05   1.65e-05     -3.914      0.000   -9.68e-05   -3.22e-05\n",
      "=============================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных\n",
    "y = data.entry_2.values\n",
    "regressors = ['served_airports_pr_period', 'neigh_airports_pr_period',\n",
    "              'airport_type', 'population', 'megapolis', 'tourist',\n",
    "              'distance_km'] # в случае добавления квадрата расстояния значимости нет и у расстояния, и у его квадрата\n",
    "X = sm.add_constant(data[regressors])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify=y) # не забыть написать про stratify=y\n",
    "\n",
    "# Пробит\n",
    "probit_model = Probit(y_train, X_train.astype(float))\n",
    "probit_model = probit_model.fit(cov_type='HC0', maxiter=1000)\n",
    "probit_predict = list(map(round,probit_model.predict(X_test)))\n",
    "print(probit_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "916db8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llr}\n",
      "\\toprule\n",
      "{} &        coef &  std err \\\\\n",
      "\\midrule\n",
      "const                     &  -2.7386*** &    0.085 \\\\\n",
      "served\\_airports\\_pr\\_period &      0.0028 &    0.004 \\\\\n",
      "neigh\\_airports\\_pr\\_period  &   0.0839*** &    0.007 \\\\\n",
      "airport\\_type              &     0.0883* &    0.046 \\\\\n",
      "population                &   0.0001*** &    0.000 \\\\\n",
      "megapolis                 &   -0.1014** &    0.049 \\\\\n",
      "tourist                   &   0.3124*** &    0.057 \\\\\n",
      "distance\\_km               &  -0.0001*** &    0.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_as_html = probit_model.summary().tables[1].as_html()\n",
    "df_probit = pd.read_html(results_as_html, header=0, index_col=0)[0]\n",
    "df_probit = df_probit[['coef','std err']]\n",
    "df_probit['coef'] = df_probit['coef'].apply(lambda row: str(round(row,4)))\n",
    "df_probit['std err'] = df_probit['std err'].apply(lambda row: round(row,4))\n",
    "df_probit.iloc[0,0] = '-2.7386***'\n",
    "df_probit.iloc[1,0] = '0.0028'\n",
    "df_probit.iloc[2,0] = '0.0839***'\n",
    "df_probit.iloc[3,0] = '0.0883*'\n",
    "df_probit.iloc[4,0] = '0.0001***'\n",
    "df_probit.iloc[5,0] = '-0.1014**'\n",
    "df_probit.iloc[6,0] = '0.3124***'\n",
    "df_probit.iloc[7,0] = '-0.0001***'\n",
    "# print(df_probit.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e881a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-2.7386***</td>\n",
       "      <td>0.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>served_airports_pr_period</th>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neigh_airports_pr_period</th>\n",
       "      <td>0.0839***</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airport_type</th>\n",
       "      <td>0.0883*</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>0.0001***</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>megapolis</th>\n",
       "      <td>-0.1014**</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tourist</th>\n",
       "      <td>0.3124***</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance_km</th>\n",
       "      <td>-0.0001***</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 coef  std err\n",
       "const                      -2.7386***    0.085\n",
       "served_airports_pr_period      0.0028    0.004\n",
       "neigh_airports_pr_period    0.0839***    0.007\n",
       "airport_type                  0.0883*    0.046\n",
       "population                  0.0001***    0.000\n",
       "megapolis                   -0.1014**    0.049\n",
       "tourist                     0.3124***    0.057\n",
       "distance_km                -0.0001***    0.000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85244f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>served_airports_pr_period</th>\n",
       "      <th>neigh_airports_pr_period</th>\n",
       "      <th>airport_type</th>\n",
       "      <th>population</th>\n",
       "      <th>megapolis</th>\n",
       "      <th>tourist</th>\n",
       "      <th>distance_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>vif</th>\n",
       "      <td>1.348069</td>\n",
       "      <td>1.404956</td>\n",
       "      <td>1.407667</td>\n",
       "      <td>2.511195</td>\n",
       "      <td>1.902185</td>\n",
       "      <td>1.895716</td>\n",
       "      <td>1.215538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     served_airports_pr_period  neigh_airports_pr_period  airport_type  \\\n",
       "vif                   1.348069                  1.404956      1.407667   \n",
       "\n",
       "     population  megapolis   tourist  distance_km  \n",
       "vif    2.511195   1.902185  1.895716     1.215538  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверка мультиколлинеарности\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "vif = [variance_inflation_factor(X.values, X.columns.get_loc(i)) for i in X.columns]\n",
    "pd.DataFrame({'vif': vif[1:]}, index=X.columns[1:]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad9981a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame()\n",
    "df_metrics['Пробит'] = [round(accuracy_score(y_test, probit_predict),3),\n",
    "                round(f1_score(y_test, probit_predict, average = 'macro'),3),\n",
    "                round(precision_score(y_test, probit_predict, average = 'macro'),3),\n",
    "                round(recall_score(y_test, probit_predict, average = 'macro'),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5c504f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики для пробита\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00     12892\n",
      "           1       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.99     12974\n",
      "   macro avg       0.50      0.50      0.50     12974\n",
      "weighted avg       0.99      0.99      0.99     12974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Метрики качества (все на тестовых данных)\n",
    "print('Метрики для пробита')\n",
    "print(classification_report(y_test, probit_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a7fcff",
   "metadata": {},
   "source": [
    "# Зависимость веса класса от его частотности: логит, случайный лес, градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76d71a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты логит модели\n",
      "                               coef\n",
      "feature                            \n",
      "neigh_airports_pr_period   1.033457\n",
      "tourist                    0.404815\n",
      "distance_km               -0.404606\n",
      "megapolis                 -0.389873\n",
      "population                 0.339319\n",
      "served_airports_pr_period -0.183179\n",
      "airport_type               0.177997\n",
      "Важность переменных в лесу (cнижение impurity)\n",
      "                           importance\n",
      "population                   0.262579\n",
      "neigh_airports_pr_period     0.230763\n",
      "distance_km                  0.191193\n",
      "served_airports_pr_period    0.149107\n",
      "tourist                      0.093142\n",
      "airport_type                 0.039299\n",
      "megapolis                    0.033917\n",
      "Важность переменных в градиентном бустинге (cнижение значения Loss функции)\n",
      "                           importance\n",
      "neigh_airports_pr_period     0.192012\n",
      "tourist                      0.005780\n",
      "airport_type                -0.000684\n",
      "distance_km                 -0.027775\n",
      "megapolis                   -0.028096\n",
      "population                  -0.050108\n",
      "served_airports_pr_period   -0.152479\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных\n",
    "y = data.entry_2.values\n",
    "regressors = ['served_airports_pr_period', 'neigh_airports_pr_period',\n",
    "              'airport_type', 'population', 'megapolis', 'tourist',\n",
    "              'distance_km'] \n",
    "X = data[regressors]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify=y)\n",
    "scaler = StandardScaler() # cкалируем данные\n",
    "X_train_scaled, X_test_scaled = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "\n",
    "# Логит\n",
    "logit_w_model = LogisticRegression(class_weight='balanced')\n",
    "logit_w_model.fit(X_train_scaled, y_train)\n",
    "logit_w_importance = pd.DataFrame({'coef':logit_w_model.coef_.reshape(7),'feature':X_train.columns}).set_index('feature')\n",
    "print('Коэффициенты логит модели')\n",
    "print(logit_w_importance.sort_values(\n",
    "    by = 'coef', key = lambda x: abs(x), ascending = False\n",
    "))\n",
    "logit_w_predict = logit_w_model.predict(X_test_scaled)\n",
    "\n",
    "# Случайный лес\n",
    "forest_w_model = RandomForestClassifier(class_weight='balanced')\n",
    "forest_w_model.fit(X_train,y_train)\n",
    "forest_w_importance = pd.DataFrame(forest_w_model.feature_importances_, index = X_train.columns, columns = ['importance'])\n",
    "print('Важность переменных в лесу (cнижение impurity)')\n",
    "print(forest_w_importance.sort_values('importance', ascending = False))\n",
    "forest_w_predict = forest_w_model.predict(X_test)\n",
    "\n",
    "# Градиентный бустинг\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "catboost_w_model = CatBoostClassifier(class_weights = class_weights, logging_level = 'Silent')\n",
    "catboost_w_model.fit(X_train,y_train)\n",
    "catboost_w_importance = pd.DataFrame(catboost_w_model.get_feature_importance(Pool(X_test, label=y_test),\n",
    "                                                                             type = \"LossFunctionChange\"), \n",
    "                                     index = X_train.columns, columns = ['importance'])\n",
    "print('Важность переменных в градиентном бустинге (cнижение значения Loss функции)')\n",
    "print(catboost_w_importance.sort_values('importance', ascending = False))\n",
    "catboost_w_predict = catboost_w_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "799c2166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# shap_values = shap.TreeExplainer(forest_w_model).shap_values(X_train) \n",
    "# shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bcb0a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics['Логит(разные веса у классов)'] = [round(accuracy_score(y_test, logit_w_predict),3),\n",
    "                round(f1_score(y_test, logit_w_predict, average = 'macro'),3),\n",
    "                round(precision_score(y_test, logit_w_predict, average = 'macro'),3),\n",
    "                round(recall_score(y_test, logit_w_predict, average = 'macro'),3)]\n",
    "\n",
    "df_metrics['Случайный лес(разные веса у классов)'] = [round(accuracy_score(y_test, forest_w_predict),3),\n",
    "                round(f1_score(y_test, forest_w_predict, average = 'macro'),3),\n",
    "                round(precision_score(y_test, forest_w_predict, average = 'macro'),3),\n",
    "                round(recall_score(y_test, forest_w_predict, average = 'macro'),3)]\n",
    "\n",
    "df_metrics['Градиентный бустинг(разные веса у классов)'] = [round(accuracy_score(y_test, catboost_w_predict),3),\n",
    "                round(f1_score(y_test, catboost_w_predict, average = 'macro'),3),\n",
    "                round(precision_score(y_test, catboost_w_predict, average = 'macro'),3),\n",
    "                round(recall_score(y_test, catboost_w_predict, average = 'macro'),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6616502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики для логита\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92     12892\n",
      "           1       0.03      0.70      0.06        82\n",
      "\n",
      "    accuracy                           0.86     12974\n",
      "   macro avg       0.51      0.78      0.49     12974\n",
      "weighted avg       0.99      0.86      0.92     12974\n",
      "\n",
      "Метрики для леса\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     12892\n",
      "           1       0.02      0.10      0.03        82\n",
      "\n",
      "    accuracy                           0.96     12974\n",
      "   macro avg       0.51      0.53      0.51     12974\n",
      "weighted avg       0.99      0.96      0.97     12974\n",
      "\n",
      "Метрики для бустинга\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     12892\n",
      "           1       0.04      0.35      0.07        82\n",
      "\n",
      "    accuracy                           0.94     12974\n",
      "   macro avg       0.52      0.65      0.52     12974\n",
      "weighted avg       0.99      0.94      0.96     12974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Метрики качества (все на тестовых данных)\n",
    "print('Метрики для логита')\n",
    "print(classification_report(y_test, logit_w_predict))\n",
    "print('Метрики для леса')\n",
    "print(classification_report(y_test, forest_w_predict))\n",
    "print('Метрики для бустинга')\n",
    "print(classification_report(y_test, catboost_w_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a10d8",
   "metadata": {},
   "source": [
    "# Ресэмплирование данных: логит, лес и бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f297aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты логит модели\n",
      "                               coef\n",
      "feature                            \n",
      "neigh_airports_pr_period   2.626483\n",
      "tourist                    0.502083\n",
      "population                 0.397428\n",
      "megapolis                 -0.356781\n",
      "distance_km               -0.350701\n",
      "airport_type               0.295872\n",
      "served_airports_pr_period -0.083333\n",
      "Важность переменных в лесу (cнижение impurity)\n",
      "                           importance\n",
      "population                   0.250020\n",
      "neigh_airports_pr_period     0.244797\n",
      "distance_km                  0.192754\n",
      "served_airports_pr_period    0.155600\n",
      "tourist                      0.088691\n",
      "airport_type                 0.039757\n",
      "megapolis                    0.028380\n",
      "Важность переменных в градиентном бустинге (cнижение значения Loss функции)\n",
      "                           importance\n",
      "neigh_airports_pr_period     0.070452\n",
      "megapolis                    0.013063\n",
      "airport_type                -0.004786\n",
      "distance_km                 -0.010213\n",
      "tourist                     -0.010778\n",
      "served_airports_pr_period   -0.036392\n",
      "population                  -0.036947\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных\n",
    "regressors = ['served_airports_pr_period', 'neigh_airports_pr_period',\n",
    "              'airport_type', 'population', 'megapolis', 'tourist',\n",
    "              'distance_km']\n",
    "X = data[regressors]\n",
    "y = data.entry_2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y, random_state=27)\n",
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "# separate minority and majority classes\n",
    "not_entry_2 = X[X.entry_2==0]\n",
    "entry_2 = X[X.entry_2==1]\n",
    "# upsample minority\n",
    "entry_2_upsampled = resample(entry_2,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(not_entry_2), # match number in majority class\n",
    "                          random_state=42) # reproducible results\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([not_entry_2, entry_2_upsampled])\n",
    "y_train = upsampled.entry_2.values\n",
    "X_train = upsampled.drop('entry_2', axis=1)\n",
    "scaler = StandardScaler() # cкалируем данные\n",
    "X_train_scaled, X_test_scaled = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "\n",
    "# Логит\n",
    "logit_s_model = LogisticRegression()\n",
    "logit_s_model.fit(X_train_scaled, y_train)\n",
    "logit_s_importance = pd.DataFrame({'coef':logit_s_model.coef_.reshape(7),'feature':X_train.columns}).set_index('feature')\n",
    "print('Коэффициенты логит модели')\n",
    "print(logit_s_importance.sort_values(\n",
    "    by = 'coef', key = lambda x: abs(x), ascending = False\n",
    "))\n",
    "logit_s_predict = logit_s_model.predict(X_test_scaled)\n",
    "\n",
    "# Случайный лес\n",
    "forest_s_model = RandomForestClassifier()\n",
    "forest_s_model.fit(X_train,y_train)\n",
    "forest_s_importance = pd.DataFrame(forest_s_model.feature_importances_, index = X_train.columns, columns = ['importance'])\n",
    "print('Важность переменных в лесу (cнижение impurity)')\n",
    "print(forest_s_importance.sort_values('importance', ascending = False))\n",
    "forest_s_predict = forest_s_model.predict(X_test)\n",
    "\n",
    "# Градиентный бустинг\n",
    "catboost_s_model = CatBoostClassifier(logging_level = 'Silent')\n",
    "catboost_s_model.fit(X_train,y_train)\n",
    "catboost_s_importance = pd.DataFrame(catboost_s_model.get_feature_importance(Pool(X_test, label=y_test),\n",
    "                                                                             type = \"LossFunctionChange\"), \n",
    "                                     index = X_train.columns, columns = ['importance'])\n",
    "print('Важность переменных в градиентном бустинге (cнижение значения Loss функции)')\n",
    "print(catboost_s_importance.sort_values('importance', ascending = False))\n",
    "catboost_s_predict = catboost_s_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ff88d8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics['Логит(случайное ресемплирование)'] = [round(accuracy_score(y_test, logit_s_predict),3),\n",
    "                round(f1_score(y_test, logit_s_predict, average = 'macro'),3),\n",
    "                round(precision_score(y_test, logit_s_predict, average = 'macro'),3),\n",
    "                round(recall_score(y_test, logit_s_predict, average = 'macro'),3)]\n",
    "\n",
    "df_metrics['Случайный лес(случайное ресемплирование)'] = [round(accuracy_score(y_test, forest_s_predict),3),\n",
    "                round(f1_score(y_test, forest_s_predict, average = 'macro'),3),\n",
    "                round(precision_score(y_test, forest_s_predict, average = 'macro'),3),\n",
    "                round(recall_score(y_test, forest_s_predict, average = 'macro'),3)]\n",
    "\n",
    "df_metrics['Градиентный бустинг(случайное ресемплирование)'] = [round(accuracy_score(y_test, catboost_s_predict),3),\n",
    "                round(f1_score(y_test, catboost_s_predict, average = 'macro'),3),\n",
    "                round(precision_score(y_test, catboost_s_predict, average = 'macro'),3),\n",
    "                round(recall_score(y_test, catboost_s_predict, average = 'macro'),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1f7ff0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики для логита\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92     12892\n",
      "           1       0.03      0.76      0.06        82\n",
      "\n",
      "    accuracy                           0.85     12974\n",
      "   macro avg       0.51      0.80      0.49     12974\n",
      "weighted avg       0.99      0.85      0.91     12974\n",
      "\n",
      "Метрики для леса\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     12892\n",
      "           1       0.01      0.07      0.02        82\n",
      "\n",
      "    accuracy                           0.96     12974\n",
      "   macro avg       0.50      0.52      0.50     12974\n",
      "weighted avg       0.99      0.96      0.97     12974\n",
      "\n",
      "Метрики для бустинга\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     12892\n",
      "           1       0.04      0.26      0.07        82\n",
      "\n",
      "    accuracy                           0.95     12974\n",
      "   macro avg       0.52      0.61      0.52     12974\n",
      "weighted avg       0.99      0.95      0.97     12974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Метрики качества (все на тестовых данных)\n",
    "print('Метрики для логита')\n",
    "print(classification_report(y_test, logit_s_predict))\n",
    "print('Метрики для леса')\n",
    "print(classification_report(y_test, forest_s_predict))\n",
    "print('Метрики для бустинга')\n",
    "print(classification_report(y_test, catboost_s_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec07be34",
   "metadata": {},
   "source": [
    "# Ресэмплирование данных с помощью SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a0a08c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты логит модели\n",
      "                               coef\n",
      "feature                            \n",
      "neigh_airports_pr_period   2.483097\n",
      "population                 0.778479\n",
      "megapolis                 -0.445552\n",
      "distance_km               -0.382262\n",
      "tourist                    0.288666\n",
      "served_airports_pr_period -0.212618\n",
      "airport_type               0.022516\n",
      "Важность переменных в лесу (cнижение impurity)\n",
      "                           importance\n",
      "population                   0.275388\n",
      "neigh_airports_pr_period     0.223677\n",
      "distance_km                  0.221763\n",
      "served_airports_pr_period    0.132742\n",
      "tourist                      0.079987\n",
      "megapolis                    0.036999\n",
      "airport_type                 0.029445\n",
      "Важность переменных в градиентном бустинге (cнижение значения Loss функции)\n",
      "                           importance\n",
      "population                   0.091211\n",
      "neigh_airports_pr_period     0.085841\n",
      "megapolis                    0.068939\n",
      "served_airports_pr_period    0.012794\n",
      "airport_type                 0.008825\n",
      "tourist                      0.007389\n",
      "distance_km                 -0.001816\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных\n",
    "y = data.entry_2.values\n",
    "regressors = ['served_airports_pr_period', 'neigh_airports_pr_period',\n",
    "              'airport_type', 'population', 'megapolis', 'tourist',\n",
    "              'distance_km'] \n",
    "X = data[regressors]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify=y)\n",
    "X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "scaler = StandardScaler() # cкалируем данные\n",
    "X_train_scaled, X_test_scaled = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "\n",
    "# Логит\n",
    "logit_smote_model = LogisticRegression()\n",
    "logit_smote_model.fit(X_train_scaled, y_train)\n",
    "logit_smote_importance = pd.DataFrame({'coef':logit_smote_model.coef_.reshape(7),'feature':X_train.columns}).set_index('feature')\n",
    "print('Коэффициенты логит модели')\n",
    "print(logit_smote_importance.sort_values(\n",
    "    by = 'coef', key = lambda x: abs(x), ascending = False\n",
    "))\n",
    "logit_smote_predict = logit_smote_model.predict(X_test_scaled)\n",
    "\n",
    "# Случайный лес\n",
    "forest_smote_model = RandomForestClassifier()\n",
    "forest_smote_model.fit(X_train,y_train)\n",
    "forest_smote_importance = pd.DataFrame(forest_smote_model.feature_importances_, index = X_train.columns, columns = ['importance'])\n",
    "print('Важность переменных в лесу (cнижение impurity)')\n",
    "print(forest_smote_importance.sort_values('importance', ascending = False))\n",
    "forest_smote_predict = forest_smote_model.predict(X_test)\n",
    "\n",
    "# Градиентный бустинг\n",
    "catboost_smote_model = CatBoostClassifier(logging_level = 'Silent')\n",
    "catboost_smote_model.fit(X_train,y_train)\n",
    "catboost_smote_importance = pd.DataFrame(catboost_smote_model.get_feature_importance(Pool(X_test, label=y_test),\n",
    "                                                                             type = \"LossFunctionChange\"), \n",
    "                                     index = X_train.columns, columns = ['importance'])\n",
    "print('Важность переменных в градиентном бустинге (cнижение значения Loss функции)')\n",
    "print(catboost_smote_importance.sort_values('importance', ascending = False))\n",
    "catboost_smote_predict = catboost_smote_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d05f2dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics['Логит(smote)'] = [round(accuracy_score(y_test, logit_smote_predict),3),\n",
    "                round(f1_score(y_test, logit_smote_predict, average = 'macro'),3),\n",
    "                round(precision_score(y_test, logit_smote_predict, average = 'macro'),3),\n",
    "                round(recall_score(y_test, logit_smote_predict, average = 'macro'),3)]\n",
    "\n",
    "df_metrics['Случайный лес(smote)'] = [round(accuracy_score(y_test, forest_smote_predict),3),\n",
    "                round(f1_score(y_test, forest_smote_predict, average = 'macro'),3),\n",
    "                round(precision_score(y_test, forest_smote_predict, average = 'macro'),3),\n",
    "                round(recall_score(y_test, forest_smote_predict, average = 'macro'),3)]\n",
    "\n",
    "df_metrics['Градиентный бустинг(smote)'] = [round(accuracy_score(y_test, catboost_smote_predict),3),\n",
    "                round(f1_score(y_test, catboost_smote_predict, average = 'macro'),3),\n",
    "                round(precision_score(y_test, catboost_smote_predict, average = 'macro'),3),\n",
    "                round(recall_score(y_test, catboost_smote_predict, average = 'macro'),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fda40bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики для логита\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93     12892\n",
      "           1       0.03      0.67      0.06        82\n",
      "\n",
      "    accuracy                           0.86     12974\n",
      "   macro avg       0.51      0.77      0.49     12974\n",
      "weighted avg       0.99      0.86      0.92     12974\n",
      "\n",
      "Метрики для леса\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98     12892\n",
      "           1       0.04      0.22      0.06        82\n",
      "\n",
      "    accuracy                           0.96     12974\n",
      "   macro avg       0.52      0.59      0.52     12974\n",
      "weighted avg       0.99      0.96      0.97     12974\n",
      "\n",
      "Метрики для бустинга\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     12892\n",
      "           1       0.05      0.38      0.08        82\n",
      "\n",
      "    accuracy                           0.95     12974\n",
      "   macro avg       0.52      0.66      0.53     12974\n",
      "weighted avg       0.99      0.95      0.97     12974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Метрики качества (все на тестовых данных)\n",
    "print('Метрики для логита')\n",
    "print(classification_report(y_test, logit_smote_predict))\n",
    "print('Метрики для леса')\n",
    "print(classification_report(y_test, forest_smote_predict))\n",
    "print('Метрики для бустинга')\n",
    "print(classification_report(y_test, catboost_smote_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf627a0",
   "metadata": {},
   "source": [
    "# Ресэмплирование данных с помощью ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dddec3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коэффициенты логит модели\n",
      "                               coef\n",
      "feature                            \n",
      "neigh_airports_pr_period   2.281484\n",
      "population                 0.825467\n",
      "distance_km               -0.456510\n",
      "megapolis                 -0.423129\n",
      "tourist                    0.249608\n",
      "served_airports_pr_period -0.144031\n",
      "airport_type              -0.100236\n",
      "Важность переменных в лесу (cнижение impurity)\n",
      "                           importance\n",
      "population                   0.278981\n",
      "distance_km                  0.236586\n",
      "neigh_airports_pr_period     0.203452\n",
      "served_airports_pr_period    0.144254\n",
      "tourist                      0.069684\n",
      "megapolis                    0.034832\n",
      "airport_type                 0.032212\n",
      "Важность переменных в градиентном бустинге (cнижение значения Loss функции)\n",
      "                           importance\n",
      "population                   0.148322\n",
      "neigh_airports_pr_period     0.089573\n",
      "megapolis                    0.073407\n",
      "distance_km                  0.018682\n",
      "airport_type                 0.012001\n",
      "served_airports_pr_period    0.007880\n",
      "tourist                      0.003620\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных\n",
    "y = data.entry_2.values\n",
    "regressors = ['served_airports_pr_period', 'neigh_airports_pr_period',\n",
    "              'airport_type', 'population', 'megapolis', 'tourist',\n",
    "              'distance_km'] \n",
    "X = data[regressors]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify=y)\n",
    "X_train, y_train = ADASYN().fit_resample(X_train, y_train)\n",
    "scaler = StandardScaler() # cкалируем данные\n",
    "X_train_scaled, X_test_scaled = scaler.fit_transform(X_train), scaler.transform(X_test)\n",
    "\n",
    "# Логит\n",
    "logit_adasyn_model = LogisticRegression()\n",
    "logit_adasyn_model.fit(X_train_scaled, y_train)\n",
    "logit_adasyn_importance = pd.DataFrame({'coef':logit_adasyn_model.coef_.reshape(7),'feature':X_train.columns}).set_index('feature')\n",
    "print('Коэффициенты логит модели')\n",
    "print(logit_adasyn_importance.sort_values(\n",
    "    by = 'coef', key = lambda x: abs(x), ascending = False\n",
    "))\n",
    "logit_adasyn_predict = logit_adasyn_model.predict(X_test_scaled)\n",
    "\n",
    "# Случайный лес\n",
    "forest_adasyn_model = RandomForestClassifier()\n",
    "forest_adasyn_model.fit(X_train,y_train)\n",
    "forest_adasyn_importance = pd.DataFrame(forest_adasyn_model.feature_importances_, index = X_train.columns, columns = ['importance'])\n",
    "print('Важность переменных в лесу (cнижение impurity)')\n",
    "print(forest_adasyn_importance.sort_values('importance', ascending = False))\n",
    "forest_adasyn_predict = forest_adasyn_model.predict(X_test)\n",
    "\n",
    "# Градиентный бустинг\n",
    "catboost_adasyn_model = CatBoostClassifier(logging_level = 'Silent')\n",
    "catboost_adasyn_model.fit(X_train,y_train)\n",
    "catboost_adasyn_importance = pd.DataFrame(catboost_adasyn_model.get_feature_importance(Pool(X_test, label=y_test),\n",
    "                                                                             type = \"LossFunctionChange\"), \n",
    "                                     index = X_train.columns, columns = ['importance'])\n",
    "print('Важность переменных в градиентном бустинге (cнижение значения Loss функции)')\n",
    "print(catboost_adasyn_importance.sort_values('importance', ascending = False))\n",
    "catboost_adasyn_predict = catboost_adasyn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bbb85adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics['Логит(adasyn)'] = [round(accuracy_score(y_test, logit_adasyn_predict),3),\n",
    "                round(f1_score(y_test, logit_adasyn_predict, average = 'macro'),3),\n",
    "                round(precision_score(y_test, logit_adasyn_predict, average = 'macro'),3),\n",
    "                round(recall_score(y_test, logit_adasyn_predict, average = 'macro'),3)]\n",
    "\n",
    "df_metrics['Случайный лес(adasyn)'] = [round(accuracy_score(y_test, forest_adasyn_predict),3),\n",
    "                round(f1_score(y_test, forest_adasyn_predict, average = 'macro'),3),\n",
    "                round(precision_score(y_test, forest_adasyn_predict, average = 'macro'),3),\n",
    "                round(recall_score(y_test, forest_adasyn_predict, average = 'macro'),3)]\n",
    "\n",
    "df_metrics['Градиентный бустинг(adasyn)'] = [round(accuracy_score(y_test, catboost_adasyn_predict),3),\n",
    "                round(f1_score(y_test, catboost_adasyn_predict, average = 'macro'),3),\n",
    "                round(precision_score(y_test, catboost_adasyn_predict, average = 'macro'),3),\n",
    "                round(recall_score(y_test, catboost_adasyn_predict, average = 'macro'),3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a0cb354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики для логита\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92     12892\n",
      "           1       0.03      0.66      0.05        82\n",
      "\n",
      "    accuracy                           0.86     12974\n",
      "   macro avg       0.51      0.76      0.49     12974\n",
      "weighted avg       0.99      0.86      0.92     12974\n",
      "\n",
      "Метрики для леса\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     12892\n",
      "           1       0.05      0.24      0.08        82\n",
      "\n",
      "    accuracy                           0.97     12974\n",
      "   macro avg       0.52      0.61      0.53     12974\n",
      "weighted avg       0.99      0.97      0.98     12974\n",
      "\n",
      "Метрики для бустинга\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     12892\n",
      "           1       0.04      0.28      0.07        82\n",
      "\n",
      "    accuracy                           0.96     12974\n",
      "   macro avg       0.52      0.62      0.53     12974\n",
      "weighted avg       0.99      0.96      0.97     12974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Метрики качества (все на тестовых данных)\n",
    "print('Метрики для логита')\n",
    "print(classification_report(y_test, logit_adasyn_predict))\n",
    "print('Метрики для леса')\n",
    "print(classification_report(y_test, forest_adasyn_predict))\n",
    "print('Метрики для бустинга')\n",
    "print(classification_report(y_test, catboost_adasyn_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6c7af5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Пробит</th>\n",
       "      <th>Логит(разные веса у классов)</th>\n",
       "      <th>Случайный лес(разные веса у классов)</th>\n",
       "      <th>Градиентный бустинг(разные веса у классов)</th>\n",
       "      <th>Логит(случайное ресемплирование)</th>\n",
       "      <th>Случайный лес(случайное ресемплирование)</th>\n",
       "      <th>Градиентный бустинг(случайное ресемплирование)</th>\n",
       "      <th>Логит(smote)</th>\n",
       "      <th>Случайный лес(smote)</th>\n",
       "      <th>Градиентный бустинг(smote)</th>\n",
       "      <th>Логит(adasyn)</th>\n",
       "      <th>Случайный лес(adasyn)</th>\n",
       "      <th>Градиентный бустинг(adasyn)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Метрика</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.993</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.943</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.498</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.497</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.497</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Пробит  Логит(разные веса у классов)  \\\n",
       "Метрика                                           \n",
       "accuracy    0.993                         0.850   \n",
       "f1-score    0.498                         0.467   \n",
       "precision   0.497                         0.501   \n",
       "recall      0.500                         0.524   \n",
       "\n",
       "           Случайный лес(разные веса у классов)  \\\n",
       "Метрика                                           \n",
       "accuracy                                  0.960   \n",
       "f1-score                                  0.494   \n",
       "precision                                 0.499   \n",
       "recall                                    0.495   \n",
       "\n",
       "           Градиентный бустинг(разные веса у классов)  \\\n",
       "Метрика                                                 \n",
       "accuracy                                        0.938   \n",
       "f1-score                                        0.488   \n",
       "precision                                       0.499   \n",
       "recall                                          0.490   \n",
       "\n",
       "           Логит(случайное ресемплирование)  \\\n",
       "Метрика                                       \n",
       "accuracy                              0.839   \n",
       "f1-score                              0.462   \n",
       "precision                             0.500   \n",
       "recall                                0.495   \n",
       "\n",
       "           Случайный лес(случайное ресемплирование)  \\\n",
       "Метрика                                               \n",
       "accuracy                                      0.961   \n",
       "f1-score                                      0.496   \n",
       "precision                                     0.500   \n",
       "recall                                        0.502   \n",
       "\n",
       "           Градиентный бустинг(случайное ресемплирование)  Логит(smote)  \\\n",
       "Метрика                                                                   \n",
       "accuracy                                            0.952         0.855   \n",
       "f1-score                                            0.494         0.468   \n",
       "precision                                           0.500         0.500   \n",
       "recall                                              0.503         0.509   \n",
       "\n",
       "           Случайный лес(smote)  Градиентный бустинг(smote)  Логит(adasyn)  \\\n",
       "Метрика                                                                      \n",
       "accuracy                  0.956                       0.943          0.849   \n",
       "f1-score                  0.490                       0.487          0.466   \n",
       "precision                 0.498                       0.497          0.500   \n",
       "recall                    0.487                       0.480          0.506   \n",
       "\n",
       "           Случайный лес(adasyn)  Градиентный бустинг(adasyn)  \n",
       "Метрика                                                        \n",
       "accuracy                   0.963                        0.952  \n",
       "f1-score                   0.497                        0.493  \n",
       "precision                  0.501                        0.500  \n",
       "recall                     0.503                        0.497  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics['Метрика'] = ['accuracy','f1-score','precision','recall']\n",
    "df_metrics = df_metrics.set_index('Метрика')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "39fa9d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_probit = df_metrics[['Пробит']]\n",
    "df_metrics_weights = df_metrics[['Логит(разные веса у классов)','Случайный лес(разные веса у классов)',\n",
    "                                 'Градиентный бустинг(разные веса у классов)']]\n",
    "df_metrics_resample = df_metrics[['Логит(случайное ресемплирование)','Случайный лес(случайное ресемплирование)',\n",
    "                                 'Градиентный бустинг(случайное ресемплирование)']]\n",
    "df_metrics_smote = df_metrics[['Логит(smote)','Случайный лес(smote)',\n",
    "                                 'Градиентный бустинг(smote)']]\n",
    "df_metrics_adasyn = df_metrics[['Логит(adasyn)','Случайный лес(adasyn)',\n",
    "                                 'Градиентный бустинг(adasyn)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a23f43d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_metrics_weights.rename(columns = {'Логит(разные веса у классов)':'Логит',\n",
    "                                     'Случайный лес(разные веса у классов)':'Случайный лес',\n",
    "                                     'Градиентный бустинг(разные веса у классов)':'Градиентный бустинг'},inplace = True)\n",
    "df_metrics_resample.rename(columns = {'Логит(случайное ресемплирование)':'Логит',\n",
    "                                     'Случайный лес(случайное ресемплирование)':'Случайный лес',\n",
    "                                     'Градиентный бустинг(случайное ресемплирование)':'Градиентный бустинг'},inplace = True)\n",
    "df_metrics_smote.rename(columns = {'Логит(smote)':'Логит',\n",
    "                                     'Случайный лес(smote)':'Случайный лес',\n",
    "                                     'Градиентный бустинг(smote)':'Градиентный бустинг'},inplace = True)\n",
    "df_metrics_adasyn.rename(columns = {'Логит(adasyn)':'Логит',\n",
    "                                     'Случайный лес(adasyn)':'Случайный лес',\n",
    "                                     'Градиентный бустинг(adasyn)':'Градиентный бустинг'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2a3cec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "{} &  Пробит \\\\\n",
      "Метрика   &         \\\\\n",
      "\\midrule\n",
      "accuracy  &   0.993 \\\\\n",
      "f1-score  &   0.498 \\\\\n",
      "precision &   0.497 \\\\\n",
      "recall    &   0.500 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_metrics_probit.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce45cc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  Логит &  Случайный лес &  Градиентный бустинг \\\\\n",
      "Метрика   &        &                &                      \\\\\n",
      "\\midrule\n",
      "accuracy  &  0.850 &          0.960 &                0.938 \\\\\n",
      "f1-score  &  0.467 &          0.494 &                0.488 \\\\\n",
      "precision &  0.501 &          0.499 &                0.499 \\\\\n",
      "recall    &  0.524 &          0.495 &                0.490 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_metrics_weights.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "070f6e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  Логит &  Случайный лес &  Градиентный бустинг \\\\\n",
      "Метрика   &        &                &                      \\\\\n",
      "\\midrule\n",
      "accuracy  &  0.839 &          0.961 &                0.952 \\\\\n",
      "f1-score  &  0.462 &          0.496 &                0.494 \\\\\n",
      "precision &  0.500 &          0.500 &                0.500 \\\\\n",
      "recall    &  0.495 &          0.502 &                0.503 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_metrics_resample.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bb996900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  Логит &  Случайный лес &  Градиентный бустинг \\\\\n",
      "Метрика   &        &                &                      \\\\\n",
      "\\midrule\n",
      "accuracy  &  0.855 &          0.956 &                0.943 \\\\\n",
      "f1-score  &  0.468 &          0.490 &                0.487 \\\\\n",
      "precision &  0.500 &          0.498 &                0.497 \\\\\n",
      "recall    &  0.509 &          0.487 &                0.480 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_metrics_smote.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f68aad32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "{} &  Логит &  Случайный лес &  Градиентный бустинг \\\\\n",
      "Метрика   &        &                &                      \\\\\n",
      "\\midrule\n",
      "accuracy  &  0.849 &          0.963 &                0.952 \\\\\n",
      "f1-score  &  0.466 &          0.497 &                0.493 \\\\\n",
      "precision &  0.500 &          0.501 &                0.500 \\\\\n",
      "recall    &  0.506 &          0.503 &                0.497 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_metrics_adasyn.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "502b9866",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_logit = pd.concat([logit_w_importance,logit_s_importance,\n",
    "                      logit_smote_importance,logit_adasyn_importance], axis = 1)\n",
    "df_logit.columns = ['Веса в функции потерь','Случайное ресемплирование','SMOTE','ADASYN']\n",
    "df_forest = pd.concat([forest_w_importance,forest_s_importance,\n",
    "                       forest_smote_importance,forest_adasyn_importance], axis = 1)\n",
    "df_forest.columns = ['Веса в функции потерь','Случайное ресемплирование','SMOTE','ADASYN']\n",
    "df_catboost = pd.concat([catboost_w_importance,catboost_s_importance,\n",
    "                         catboost_smote_importance,catboost_adasyn_importance], axis = 1)\n",
    "df_catboost.columns = ['Веса в функции потерь','Случайное ресемплирование','SMOTE','ADASYN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "06e59e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &  Веса в функции потерь &  Случайное ресемплирование &     SMOTE &    ADASYN \\\\\n",
      "feature                   &                        &                            &           &           \\\\\n",
      "\\midrule\n",
      "served\\_airports\\_pr\\_period &              -0.183179 &                  -0.083333 & -0.212618 & -0.144031 \\\\\n",
      "neigh\\_airports\\_pr\\_period  &               1.033457 &                   2.626483 &  2.483097 &  2.281484 \\\\\n",
      "airport\\_type              &               0.177997 &                   0.295872 &  0.022516 & -0.100236 \\\\\n",
      "population                &               0.339319 &                   0.397428 &  0.778479 &  0.825467 \\\\\n",
      "megapolis                 &              -0.389873 &                  -0.356781 & -0.445552 & -0.423129 \\\\\n",
      "tourist                   &               0.404815 &                   0.502083 &  0.288666 &  0.249608 \\\\\n",
      "distance\\_km               &              -0.404606 &                  -0.350701 & -0.382262 & -0.456510 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_logit.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "34ad307b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &  Веса в функции потерь &  Случайное ресемплирование &     SMOTE &    ADASYN \\\\\n",
      "\\midrule\n",
      "served\\_airports\\_pr\\_period &               0.149107 &                   0.155600 &  0.132742 &  0.144254 \\\\\n",
      "neigh\\_airports\\_pr\\_period  &               0.230763 &                   0.244797 &  0.223677 &  0.203452 \\\\\n",
      "airport\\_type              &               0.039299 &                   0.039757 &  0.029445 &  0.032212 \\\\\n",
      "population                &               0.262579 &                   0.250020 &  0.275388 &  0.278981 \\\\\n",
      "megapolis                 &               0.033917 &                   0.028380 &  0.036999 &  0.034832 \\\\\n",
      "tourist                   &               0.093142 &                   0.088691 &  0.079987 &  0.069684 \\\\\n",
      "distance\\_km               &               0.191193 &                   0.192754 &  0.221763 &  0.236586 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_forest.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1dd02c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &  Веса в функции потерь &  Случайное ресемплирование &     SMOTE &    ADASYN \\\\\n",
      "\\midrule\n",
      "served\\_airports\\_pr\\_period &              -0.152479 &                  -0.036392 &  0.012794 &  0.007880 \\\\\n",
      "neigh\\_airports\\_pr\\_period  &               0.192012 &                   0.070452 &  0.085841 &  0.089573 \\\\\n",
      "airport\\_type              &              -0.000684 &                  -0.004786 &  0.008825 &  0.012001 \\\\\n",
      "population                &              -0.050108 &                  -0.036947 &  0.091211 &  0.148322 \\\\\n",
      "megapolis                 &              -0.028096 &                   0.013063 &  0.068939 &  0.073407 \\\\\n",
      "tourist                   &               0.005780 &                  -0.010778 &  0.007389 &  0.003620 \\\\\n",
      "distance\\_km               &              -0.027775 &                  -0.010213 & -0.001816 &  0.018682 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df_catboost.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8adcf89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
